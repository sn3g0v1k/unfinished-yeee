Unfinished Yeee

Коротко: десктоп-приложение на Python + Flet для создания голосовых заметок. Записывает голос с микрофона, распознаёт речь (speech_recognition), отправляет текст в OpenRouter (или другой совместимый LLM API) для структурирования и редактирования, и сохраняет результат в Markdown (.md).
Статус

Проект не завершён. Выкладываю код как есть — PR и contributions приветствуются.
Ключевые возможности

    Запись голосовой заметки с микрофона
    Распознавание речи (speech_recognition)
    Отправка текста в OpenRouter API для структурирования/редактирования
    Экспорт итоговой заметки в формат .md
    GUI реализован с использованием Flet (ПК)

Требования

    Python 3.10+ (рекомендуется)
    Механизм записи и распознавания речи: микрофон и драйверы OS
    Токен/ключ OpenRouter API

Установка

    Клонировать репозиторий:

bash

git clone https://github.com/sn3g0v1k/unfinished-yeee.git
cd unfinished-yeee

    Создать виртуальное окружение и установить зависимости:

bash

python -m venv venv
# Linux / macOS
source venv/bin/activate
# Windows
venv\Scripts\activate

pip install -r requirements.txt

Если requirements.txt не содержит всех нужных пакетов, установите вручную:

bash

pip install flet speechrecognition openai requests pydub

(Замените/дополните список при необходимости: openrouter-клиент, sounddevice и т.д.)
Конфигурация

    Создайте файл .env или экспортируйте переменную окружения:

    OPENROUTER_API_KEY (или другой ключ, используемый в коде)
    При необходимости: OPENROUTER_BASE_URL

Пример .env:

Code

OPENROUTER_API_KEY=your_api_key_here

    Проверьте в коде (config/ или main файл), какие переменные ожидаются, и при необходимости обновите имена переменных.

Запуск

bash

# при активном виртуальном окружении
python main.py

(Или другой стартовый файл, если в репозитории он называется иначе — замените на фактическое имя.)
Как это работает (вкратце)

    GUI (Flet) предоставляет кнопку/интерфейс для записи.
    Записывается аудио с микрофона (например, через speech_recognition или pyaudio).
    Аудио конвертируется в текст (speech_recognition).
    Текст отправляется в OpenRouter API с инструкцией: "структурируй, исправь, оформи в Markdown".
    Результат показывается в GUI и сохраняется как .md-файл.

Структура репозитория (пример)

    main.py — входная точка приложения (GUI)
    recorder.py — модуль записи аудио
    recognizer.py — обёртка для speech_recognition
    openrouter_client.py — взаимодействие с OpenRouter API
    utils.py — вспомогательные функции (сохранение .md и т.д.)
    requirements.txt
    README.md

(Актуализируйте названия файлов под ваш код.)
Примеры использования

    Нажать «Record», говорить, нажать «Stop»
    Дождаться распознавания → редактирования AI → сохранить заметку как my_note.md

Что нужно доделать / TODO

    Обработка ошибок сети и API-лимитов
    Очистка и нормализация аудио (шумоподавление)
    Поддержка нескольких языков
    UI/UX: индикаторы прогресса, предпросмотр Markdown
    Добавить тесты и CI
    Документация по установке и отладке API-ключей

Вклад

PR/Issues приветствуются. Опишите проблему или фичу, прикладывайте логи/скриншоты. Для крупных изменений создавайте ветку feature/xxx.
Лицензия

Добавьте файл LICENSE с желаемой лицензией (MIT/GPL/прочее). Временно проект не лицензирован.
